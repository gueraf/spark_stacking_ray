apiVersion: "kubeflow.org/v1"
kind: PyTorchJob
metadata:
  name: pytorch-gpu-test
spec:
  pytorchReplicaSpecs:
    Master:
      replicas: 1
      restartPolicy: OnFailure
      template:
        spec:
          hostNetwork: true
          dnsPolicy: ClusterFirstWithHostNet
          tolerations:
            - key: "nvidia.com/gpu"
              operator: "Exists"
              effect: "NoSchedule"
          containers:
            - name: pytorch
              image: ray_nccl_node:latest
              imagePullPolicy: Never
              env:
                - name: NCCL_DEBUG
                  value: "INFO"
              resources:
                limits:
                  nvidia.com/gpu: 1
              command: ["/bin/bash", "-c"]
              args:
                - |
                  set -e
                  set -x
                  
                  # Create the python script
                  cat << 'EOF' > /tmp/test.py
                  import torch
                  import torch.distributed as dist
                  import os
                  import socket
                  import sys

                  rank = int(os.environ.get('RANK', 0))
                  ws = int(os.environ.get('WORLD_SIZE', 1))
                  host = socket.gethostname()

                  print(f'[{host}] Rank {rank}/{ws} Initializing...')

                  if not torch.cuda.is_available():
                      print(f'[{host}] ERROR: CUDA not available')
                      sys.exit(1)
                      
                  device = torch.device('cuda:0')
                  print(f'[{host}] Using GPU: {torch.cuda.get_device_name(device)}')

                  # Initialize Process Group
                  # We use nccl backend as requested
                  dist.init_process_group(backend='nccl')

                  val = 1.0
                  tensor = torch.tensor([val]).to(device)
                  print(f'[{host}] Local Tensor: {tensor.item()}')

                  # All Reduce (Sum)
                  dist.all_reduce(tensor, op=dist.ReduceOp.SUM)
                  result = tensor.item()

                  expected = val * ws
                  print(f'[{host}] Result: {result}')

                  dist.destroy_process_group()

                  if abs(result - expected) < 1e-6:
                      print(f'[{host}] VALIDATION SUCCESS: {result} == {expected}')
                  else:
                      print(f'[{host}] VALIDATION FAILURE: {result} != {expected}')
                      sys.exit(1)
                  EOF

                  # Auto-detect interface name for NCCL (must be interface name, not IP!)
                  # List network interfaces and pick first non-loopback one
                  export NCCL_SOCKET_IFNAME=$(ls /sys/class/net | grep -v lo | head -n1)
                  if [ -z "$NCCL_SOCKET_IFNAME" ]; then
                    export NCCL_SOCKET_IFNAME=eth0
                  fi
                  echo "Detected NCCL Interface: $NCCL_SOCKET_IFNAME"

                  # Debug: Check GPU visibility
                  echo ">>> Checking GPU visibility:"
                  nvidia-smi
                  
                  # Run with UV, forcing CUDA torch (nightly for Blackwell sm_121 support)
                  echo "Running test with uv (CUDA nightly for GB10/Blackwell)..."
                  uv run --with "torch" --extra-index-url https://download.pytorch.org/whl/nightly/cu126 /tmp/test.py
    Worker:
      replicas: 1
      restartPolicy: OnFailure
      template:
        spec:
          hostNetwork: true
          dnsPolicy: ClusterFirstWithHostNet
          tolerations:
            - key: "nvidia.com/gpu"
              operator: "Exists"
              effect: "NoSchedule"
          containers:
            - name: pytorch
              image: ray_nccl_node:latest
              imagePullPolicy: Never
              env:
                - name: NCCL_DEBUG
                  value: "INFO"
              resources:
                limits:
                  nvidia.com/gpu: 1
              command: ["/bin/bash", "-c"]
              args:
                - |
                  set -e
                  set -x
                  
                  cat << 'EOF' > /tmp/test.py
                  import torch
                  import torch.distributed as dist
                  import os
                  import socket
                  import sys

                  rank = int(os.environ.get('RANK', 0))
                  ws = int(os.environ.get('WORLD_SIZE', 1))
                  host = socket.gethostname()

                  print(f'[{host}] Rank {rank}/{ws} Initializing...')

                  if not torch.cuda.is_available():
                      print(f'[{host}] ERROR: CUDA not available')
                      sys.exit(1)
                      
                  device = torch.device('cuda:0')
                  print(f'[{host}] Using GPU: {torch.cuda.get_device_name(device)}')

                  dist.init_process_group(backend='nccl')

                  val = 1.0
                  tensor = torch.tensor([val]).to(device)
                  print(f'[{host}] Local Tensor: {tensor.item()}')

                  dist.all_reduce(tensor, op=dist.ReduceOp.SUM)
                  result = tensor.item()

                  expected = val * ws
                  print(f'[{host}] Result: {result}')

                  dist.destroy_process_group()

                  if abs(result - expected) < 1e-6:
                      print(f'[{host}] VALIDATION SUCCESS: {result} == {expected}')
                  else:
                      print(f'[{host}] VALIDATION FAILURE: {result} != {expected}')
                      sys.exit(1)
                  EOF

                  # Auto-detect interface name for NCCL (must be interface name, not IP!)
                  export NCCL_SOCKET_IFNAME=$(ls /sys/class/net | grep -v lo | head -n1)
                  if [ -z "$NCCL_SOCKET_IFNAME" ]; then
                    export NCCL_SOCKET_IFNAME=eth0
                  fi
                  echo "Detected NCCL Interface: $NCCL_SOCKET_IFNAME"
                  
                  echo ">>> Checking GPU visibility:"
                  nvidia-smi
                  
                  echo "Running test with uv (CUDA nightly for GB10/Blackwell)..."
                  uv run --with "torch" --extra-index-url https://download.pytorch.org/whl/nightly/cu126 /tmp/test.py
